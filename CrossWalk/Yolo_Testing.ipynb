{
 "cells": [
  {
   "metadata": {},
   "cell_type": "code",
   "source": "from ultralytics import YOLO",
   "id": "b4610119559bb321",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-25T12:13:19.642256Z",
     "start_time": "2024-06-25T12:12:15.485095Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from ultralytics import YOLO\n",
    "\n",
    "# Load a model\n",
    "model = YOLO(\"yolov8n.yaml\")  # build a new model from scratch\n",
    "\n",
    "results = model(\"./test_000001.jpg\")  # predict on an image\n",
    "path = model.export(format=\"onnx\")  # export the model to ONNX format"
   ],
   "id": "fa802d6018d42d4",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 C:\\Users\\paco2\\Documents\\GitHub\\MachineLearningProyect\\CrossWalk\\test_000001.jpg: 448x640 (no detections), 342.3ms\n",
      "Speed: 9.0ms preprocess, 342.3ms inference, 19.0ms postprocess per image at shape (1, 3, 448, 640)\n",
      "Ultralytics YOLOv8.2.35  Python-3.11.9 torch-2.3.1+cpu CPU (Intel Core(TM) i7-9750H 2.60GHz)\n",
      "\n",
      "\u001B[34m\u001B[1mPyTorch:\u001B[0m starting from 'yolov8n.yaml' with input shape (1, 3, 640, 640) BCHW and output shape(s) (1, 84, 8400) (0.0 MB)\n",
      "\u001B[31m\u001B[1mrequirements:\u001B[0m Ultralytics requirement ['onnx>=1.12.0'] not found, attempting AutoUpdate...\n",
      "Collecting onnx>=1.12.0\r\n",
      "  Obtaining dependency information for onnx>=1.12.0 from https://files.pythonhosted.org/packages/b2/88/974de6816540a0e770e323425b0291784556063c7b0754bbbdbb86fb3716/onnx-1.16.1-cp311-cp311-win_amd64.whl.metadata\r\n",
      "  Downloading onnx-1.16.1-cp311-cp311-win_amd64.whl.metadata (16 kB)\r\n",
      "Requirement already satisfied: numpy>=1.20 in c:\\users\\paco2\\documents\\github\\machinelearningproyect\\new\\env\\lib\\site-packages (from onnx>=1.12.0) (1.26.4)\r\n",
      "Requirement already satisfied: protobuf>=3.20.2 in c:\\users\\paco2\\documents\\github\\machinelearningproyect\\new\\env\\lib\\site-packages (from onnx>=1.12.0) (4.25.3)\r\n",
      "Downloading onnx-1.16.1-cp311-cp311-win_amd64.whl (14.4 MB)\r\n",
      "   ---------------------------------------- 14.4/14.4 MB 962.6 kB/s eta 0:00:00\r\n",
      "Installing collected packages: onnx\r\n",
      "Successfully installed onnx-1.16.1\r\n",
      "\n",
      "\u001B[31m\u001B[1mrequirements:\u001B[0m AutoUpdate success  54.1s, installed 1 package: ['onnx>=1.12.0']\n",
      "\u001B[31m\u001B[1mrequirements:\u001B[0m  \u001B[1mRestart runtime or rerun command for updates to take effect\u001B[0m\n",
      "\n",
      "\n",
      "\u001B[34m\u001B[1mONNX:\u001B[0m starting export with onnx 1.16.1 opset 17...\n",
      "\u001B[34m\u001B[1mONNX:\u001B[0m export success  58.1s, saved as 'yolov8n.onnx' (12.2 MB)\n",
      "\n",
      "Export complete (61.2s)\n",
      "Results saved to \u001B[1mC:\\Users\\paco2\\Documents\\GitHub\\MachineLearningProyect\\CrossWalk\u001B[0m\n",
      "Predict:         yolo predict task=detect model=yolov8n.onnx imgsz=640  \n",
      "Validate:        yolo val task=detect model=yolov8n.onnx imgsz=640 data=None  \n",
      "Visualize:       https://netron.app\n"
     ]
    }
   ],
   "execution_count": 4
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-25T12:17:40.771484Z",
     "start_time": "2024-06-25T12:17:40.760929Z"
    }
   },
   "cell_type": "code",
   "source": [
    "for result in results:\n",
    "    boxes = result.boxes  # Obtener las cajas delimitadoras de los objetos\n",
    "    for box in boxes:\n",
    "        # Acceder a los atributos de cada objeto detectado\n",
    "        x1, y1, x2, y2 = box.xyxy  # Coordenadas de la caja delimitadora\n",
    "        conf = box.conf  # Confianza de la detección\n",
    "        cls = box.cls  # Clase del objeto detectado\n",
    "        print(f\"Objeto detectado: Clase={int(cls)}, Confianza={conf:.2f}, Coordenadas=({x1:.0f},{y1:.0f},{x2:.0f},{y2:.0f})\")\n",
    "print(\"i\")"
   ],
   "id": "c71c92c00191471a",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "i\n"
     ]
    }
   ],
   "execution_count": 15
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-25T12:19:06.485013Z",
     "start_time": "2024-06-25T12:19:06.477506Z"
    }
   },
   "cell_type": "code",
   "source": [
    "for result in results:\n",
    "    names = result.names\n",
    "    for i, name in names.items():\n",
    "        print(f\"Clase {i}: {name}\")\n",
    "        "
   ],
   "id": "c5ac8a1f42c905bd",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Clase 0: 0\n",
      "Clase 1: 1\n",
      "Clase 2: 2\n",
      "Clase 3: 3\n",
      "Clase 4: 4\n",
      "Clase 5: 5\n",
      "Clase 6: 6\n",
      "Clase 7: 7\n",
      "Clase 8: 8\n",
      "Clase 9: 9\n",
      "Clase 10: 10\n",
      "Clase 11: 11\n",
      "Clase 12: 12\n",
      "Clase 13: 13\n",
      "Clase 14: 14\n",
      "Clase 15: 15\n",
      "Clase 16: 16\n",
      "Clase 17: 17\n",
      "Clase 18: 18\n",
      "Clase 19: 19\n",
      "Clase 20: 20\n",
      "Clase 21: 21\n",
      "Clase 22: 22\n",
      "Clase 23: 23\n",
      "Clase 24: 24\n",
      "Clase 25: 25\n",
      "Clase 26: 26\n",
      "Clase 27: 27\n",
      "Clase 28: 28\n",
      "Clase 29: 29\n",
      "Clase 30: 30\n",
      "Clase 31: 31\n",
      "Clase 32: 32\n",
      "Clase 33: 33\n",
      "Clase 34: 34\n",
      "Clase 35: 35\n",
      "Clase 36: 36\n",
      "Clase 37: 37\n",
      "Clase 38: 38\n",
      "Clase 39: 39\n",
      "Clase 40: 40\n",
      "Clase 41: 41\n",
      "Clase 42: 42\n",
      "Clase 43: 43\n",
      "Clase 44: 44\n",
      "Clase 45: 45\n",
      "Clase 46: 46\n",
      "Clase 47: 47\n",
      "Clase 48: 48\n",
      "Clase 49: 49\n",
      "Clase 50: 50\n",
      "Clase 51: 51\n",
      "Clase 52: 52\n",
      "Clase 53: 53\n",
      "Clase 54: 54\n",
      "Clase 55: 55\n",
      "Clase 56: 56\n",
      "Clase 57: 57\n",
      "Clase 58: 58\n",
      "Clase 59: 59\n",
      "Clase 60: 60\n",
      "Clase 61: 61\n",
      "Clase 62: 62\n",
      "Clase 63: 63\n",
      "Clase 64: 64\n",
      "Clase 65: 65\n",
      "Clase 66: 66\n",
      "Clase 67: 67\n",
      "Clase 68: 68\n",
      "Clase 69: 69\n",
      "Clase 70: 70\n",
      "Clase 71: 71\n",
      "Clase 72: 72\n",
      "Clase 73: 73\n",
      "Clase 74: 74\n",
      "Clase 75: 75\n",
      "Clase 76: 76\n",
      "Clase 77: 77\n",
      "Clase 78: 78\n",
      "Clase 79: 79\n"
     ]
    }
   ],
   "execution_count": 19
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-25T12:24:17.058226Z",
     "start_time": "2024-06-25T12:24:17.035429Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import cv2\n",
    "\n",
    "# Cargar la imagen original\n",
    "orig_img = cv2.imread(\"test_000001.jpg\")"
   ],
   "id": "fa4fc3eb2e0327e2",
   "outputs": [],
   "execution_count": 23
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-25T12:25:28.620695Z",
     "start_time": "2024-06-25T12:25:28.610423Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Iterar sobre los resultados de la detección\n",
    "for result in results:\n",
    "    boxes = result.boxes\n",
    "    for box in boxes:\n",
    "        # Obtener las coordenadas de la caja delimitadora\n",
    "        x1, y1, x2, y2 = box.xyxy[0]\n",
    "        x1, y1, x2, y2 = int(x1), int(y1), int(x2), int(y2)\n",
    "        \n",
    "        # Dibujar la caja delimitadora\n",
    "        cv2.rectangle(orig_img, (x1, y1), (x2, y2), (0, 255, 0), 2)\n",
    "        \n",
    "        # Obtener la clase del objeto detectado\n",
    "        cls = int(box.cls[0])\n",
    "        label = result.names[cls]\n",
    "        \n",
    "        # Dibujar la etiqueta del objeto\n",
    "        (label_width, label_height), _ = cv2.getTextSize(label, cv2.FONT_HERSHEY_SIMPLEX, 0.5, 1)\n",
    "        cv2.rectangle(orig_img, (x1, y1 - label_height - 10), (x1 + label_width, y1), (0, 255, 0), -1)\n",
    "        cv2.putText(orig_img, label, (x1, y1 - 5), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (255, 255, 255), 1)"
   ],
   "id": "fb802ce35ca21516",
   "outputs": [],
   "execution_count": 26
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-25T12:25:31.474152Z",
     "start_time": "2024-06-25T12:25:29.227745Z"
    }
   },
   "cell_type": "code",
   "source": [
    "cv2.imshow(\"Imagen con detecciones\", orig_img)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ],
   "id": "52aa16c068db257f",
   "outputs": [],
   "execution_count": 27
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-25T12:30:25.234231Z",
     "start_time": "2024-06-25T12:30:14.431933Z"
    }
   },
   "cell_type": "code",
   "source": [
    "source = \"C:/Users/paco2/Documents/GitHub/MachineLearningProyect/CrossWalk/test_000001.jpg\"\n",
    "!yolo predict model=yolov8n.pt source=source"
   ],
   "id": "a99d10173502d636",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ultralytics YOLOv8.2.35 ðŸš€ Python-3.11.9 torch-2.3.1+cpu CPU (Intel Core(TM) i7-9750H 2.60GHz)\n",
      "YOLOv8n summary (fused): 168 layers, 3151904 parameters, 0 gradients, 8.7 GFLOPs\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"<frozen runpy>\", line 198, in _run_module_as_main\n",
      "  File \"<frozen runpy>\", line 88, in _run_code\n",
      "  File \"C:\\Users\\paco2\\Documents\\GitHub\\MachineLearningProyect\\new\\env\\Scripts\\yolo.exe\\__main__.py\", line 7, in <module>\n",
      "  File \"C:\\Users\\paco2\\Documents\\GitHub\\MachineLearningProyect\\new\\env\\Lib\\site-packages\\ultralytics\\cfg\\__init__.py\", line 591, in entrypoint\n",
      "    getattr(model, mode)(**overrides)  # default args from model\n",
      "    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\paco2\\Documents\\GitHub\\MachineLearningProyect\\new\\env\\Lib\\site-packages\\ultralytics\\engine\\model.py\", line 453, in predict\n",
      "    return self.predictor.predict_cli(source=source) if is_cli else self.predictor(source=source, stream=stream)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\paco2\\Documents\\GitHub\\MachineLearningProyect\\new\\env\\Lib\\site-packages\\ultralytics\\engine\\predictor.py\", line 183, in predict_cli\n",
      "    for _ in gen:  # sourcery skip: remove-empty-nested-block, noqa\n",
      "  File \"C:\\Users\\paco2\\Documents\\GitHub\\MachineLearningProyect\\new\\env\\Lib\\site-packages\\torch\\utils\\_contextlib.py\", line 35, in generator_context\n",
      "    response = gen.send(None)\n",
      "               ^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\paco2\\Documents\\GitHub\\MachineLearningProyect\\new\\env\\Lib\\site-packages\\ultralytics\\engine\\predictor.py\", line 226, in stream_inference\n",
      "    self.setup_source(source if source is not None else self.args.source)\n",
      "  File \"C:\\Users\\paco2\\Documents\\GitHub\\MachineLearningProyect\\new\\env\\Lib\\site-packages\\ultralytics\\engine\\predictor.py\", line 198, in setup_source\n",
      "    self.dataset = load_inference_source(\n",
      "                   ^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\paco2\\Documents\\GitHub\\MachineLearningProyect\\new\\env\\Lib\\site-packages\\ultralytics\\data\\build.py\", line 202, in load_inference_source\n",
      "    dataset = LoadImagesAndVideos(source, batch=batch, vid_stride=vid_stride)\n",
      "              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\paco2\\Documents\\GitHub\\MachineLearningProyect\\new\\env\\Lib\\site-packages\\ultralytics\\data\\loaders.py\", line 292, in __init__\n",
      "    raise FileNotFoundError(f\"{p} does not exist\")\n",
      "FileNotFoundError: source does not exist\n"
     ]
    }
   ],
   "execution_count": 30
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-25T12:17:45.184951Z",
     "start_time": "2024-06-25T12:17:45.177729Z"
    }
   },
   "cell_type": "code",
   "source": "print(results)",
   "id": "e9ea3a3964adafb0",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ultralytics.engine.results.Results object with attributes:\n",
      "\n",
      "boxes: ultralytics.engine.results.Boxes object\n",
      "keypoints: None\n",
      "masks: None\n",
      "names: {0: '0', 1: '1', 2: '2', 3: '3', 4: '4', 5: '5', 6: '6', 7: '7', 8: '8', 9: '9', 10: '10', 11: '11', 12: '12', 13: '13', 14: '14', 15: '15', 16: '16', 17: '17', 18: '18', 19: '19', 20: '20', 21: '21', 22: '22', 23: '23', 24: '24', 25: '25', 26: '26', 27: '27', 28: '28', 29: '29', 30: '30', 31: '31', 32: '32', 33: '33', 34: '34', 35: '35', 36: '36', 37: '37', 38: '38', 39: '39', 40: '40', 41: '41', 42: '42', 43: '43', 44: '44', 45: '45', 46: '46', 47: '47', 48: '48', 49: '49', 50: '50', 51: '51', 52: '52', 53: '53', 54: '54', 55: '55', 56: '56', 57: '57', 58: '58', 59: '59', 60: '60', 61: '61', 62: '62', 63: '63', 64: '64', 65: '65', 66: '66', 67: '67', 68: '68', 69: '69', 70: '70', 71: '71', 72: '72', 73: '73', 74: '74', 75: '75', 76: '76', 77: '77', 78: '78', 79: '79'}\n",
      "obb: None\n",
      "orig_img: array([[[243, 228, 226],\n",
      "        [244, 231, 229],\n",
      "        [244, 231, 229],\n",
      "        ...,\n",
      "        [ 15,  13,  13],\n",
      "        [ 28,  27,  29],\n",
      "        [  6,   9,  13]],\n",
      "\n",
      "       [[241, 232, 222],\n",
      "        [241, 232, 222],\n",
      "        [243, 234, 225],\n",
      "        ...,\n",
      "        [ 20,  18,  17],\n",
      "        [ 22,  22,  22],\n",
      "        [  7,   9,  10]],\n",
      "\n",
      "       [[242, 233, 224],\n",
      "        [237, 228, 219],\n",
      "        [238, 231, 222],\n",
      "        ...,\n",
      "        [  2,   0,   0],\n",
      "        [  7,   7,   7],\n",
      "        [  8,  10,  11]],\n",
      "\n",
      "       ...,\n",
      "\n",
      "       [[  5,  12,   7],\n",
      "        [ 11,  16,  14],\n",
      "        [  8,   8,   8],\n",
      "        ...,\n",
      "        [ 31,  32,  36],\n",
      "        [ 32,  34,  35],\n",
      "        [ 29,  31,  31]],\n",
      "\n",
      "       [[ 18,  32,  26],\n",
      "        [ 13,  22,  19],\n",
      "        [  7,  12,  11],\n",
      "        ...,\n",
      "        [ 32,  33,  37],\n",
      "        [ 31,  33,  34],\n",
      "        [ 26,  28,  28]],\n",
      "\n",
      "       [[ 18,  36,  29],\n",
      "        [  2,  17,  13],\n",
      "        [  1,  12,  10],\n",
      "        ...,\n",
      "        [ 31,  32,  36],\n",
      "        [ 30,  32,  33],\n",
      "        [ 23,  28,  27]]], dtype=uint8)\n",
      "orig_shape: (419, 640)\n",
      "path: 'C:\\\\Users\\\\paco2\\\\Documents\\\\GitHub\\\\MachineLearningProyect\\\\CrossWalk\\\\test_000001.jpg'\n",
      "probs: None\n",
      "save_dir: 'runs\\\\detect\\\\predict'\n",
      "speed: {'preprocess': 9.000539779663086, 'inference': 342.27514266967773, 'postprocess': 19.002437591552734}]\n"
     ]
    }
   ],
   "execution_count": 16
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-25T12:38:20.419289Z",
     "start_time": "2024-06-25T12:38:17.280300Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from ultralytics import YOLO\n",
    "import cv2\n",
    "\n",
    "# Cargar el modelo YOLO v8\n",
    "model = YOLO(\"yolov8n.pt\")\n",
    "\n",
    "# Definir la ruta de la imagen\n",
    "sourceCD = r\"C:\\Users\\paco2\\Documents\\GitHub\\MachineLearningProyect\\CrossWalk\\test_000007.jpg\"\n",
    "# Cargar la imagen original\n",
    "orig_img = cv2.imread(sourceCD)\n",
    "# Realizar la predicción\n",
    "results = model.predict(source=sourceCD)\n",
    "\n",
    "# Iterar sobre los resultados de la detección\n",
    "for result in results:\n",
    "    boxes = result.boxes\n",
    "    for box in boxes:\n",
    "        # Obtener las coordenadas de la caja delimitadora\n",
    "        x1, y1, x2, y2 = box.xyxy[0]\n",
    "        x1, y1, x2, y2 = int(x1), int(y1), int(x2), int(y2)\n",
    "        \n",
    "        # Dibujar la caja delimitadora\n",
    "        cv2.rectangle(orig_img, (x1, y1), (x2, y2), (0, 255, 0), 2)\n",
    "        \n",
    "        # Obtener la clase del objeto detectado\n",
    "        cls = int(box.cls[0])\n",
    "        label = result.names[cls]\n",
    "        \n",
    "        # Dibujar la etiqueta del objeto\n",
    "        (label_width, label_height), _ = cv2.getTextSize(label, cv2.FONT_HERSHEY_SIMPLEX, 0.5, 1)\n",
    "        cv2.rectangle(orig_img, (x1, y1 - label_height - 10), (x1 + label_width, y1), (0, 255, 0), -1)\n",
    "        cv2.putText(orig_img, label, (x1, y1 - 5), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (255, 255, 255), 1)\n",
    "\n",
    "# Guardar la imagen con los objetos detectados\n",
    "cv2.imwrite(\"imagen_con_detecciones.jpg\", orig_img)"
   ],
   "id": "ae8513f43f9c6177",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 C:\\Users\\paco2\\Documents\\GitHub\\MachineLearningProyect\\CrossWalk\\test_000007.jpg: 480x640 8 persons, 3 bicycles, 3 cars, 1 motorcycle, 5 traffic lights, 2 backpacks, 341.1ms\n",
      "Speed: 5.0ms preprocess, 341.1ms inference, 5.0ms postprocess per image at shape (1, 3, 480, 640)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 7
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-25T13:47:13.070371Z",
     "start_time": "2024-06-25T13:46:54.148798Z"
    }
   },
   "cell_type": "code",
   "source": [
    "cv2.imshow(\"Imagen con detecciones\", orig_img)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ],
   "id": "b1ee3e189247d222",
   "outputs": [],
   "execution_count": 9
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "4a146b31cc53f285"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
